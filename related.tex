\begin{flushleft}
\centering \section*{Предшествующие работы}
\centering \subsection*{Задача выбора порядка соединений}

В статье "On the Optimal Nesting Order for Computing N-Relational Joins" --- Ibaraki \& Kameda (1984) формализуется задача выбора оптимального порядка соединения $n$ отношений,
при использовании вложенного цикла для сканирования таблиц и результатов соединений. \textbf{Оптимальный вложенный порядок}.
Для заданного набора отношений и предикатов соединения выводится формула ожидаемого числа чтений страниц как функция от порядка соединяемых отношений,
и требуется найти порядок, минимизирующий это значение. Авторы прямо отмечают, что задача нахождения минимального значения этой функции NP-трудная.

Задача выбора оптимального вложенного порядка принимает на вход:
\begin{enumerate}
  \item Статистики для формулы ожидаемого числа чтений страниц.
  \item Описание запроса (граф соединений).
  \item Пороговое значение $B$ --- существует ли такой порядок вложенности отношений, что число чтений страниц $\le B$?
\end{enumerate}

\centering \subsection*{Принадлежность NP}

Если мы угадали порядок отношений $\pi$, то значение функции числа чтений страниц для $\pi$ вычисляется полиномиально по размеру входа
(это просто вычисление выражения по заданным параметрам). Значит, решение можно проверить за полиномиальное время, тогда задача принадлежит NP.

\centering \subsection*{NP-трудность}

В доказательстве NP-трудности авторы сводят к этой задаче классическую NP-полную задачу поиска полного графа (Робин Карп, 1972):
по графу $G=(V,E)$ и числу $k$ строится экземпляр запроса (в терминах отношений и условий соединения) и подбираются параметры стоимости так, что
существует порядок с числом чтений страниц $\leq B$ тогда и только тогда, когда в $G$ есть полный граф размера $k$.

\centering \subsection*{Пространство поиска планов}

Пусть даны два отношения R1 и R2, и дан результат их соединения $(R1 \Join R2)$. Назовём R1 - левым сыном, R2 - правым сыном, 
а результат соединения родителем. Тогда получится двоичное дерево. Каждому возможному порядку соединения исходного набора таблиц 
сопоставим двоичное дерево.
\newline
[p493: On the Correct and Complete Enumeration of the Core Search Space (2013)]

Для заданного начального  дерева  \textbf{Пространство поиска планов} — это множество всех различных порядков, которые можно получить, 
применяя к начальному плану последовательность из корректных преобразований (они сохраняют эквивалентность результатов, т.е семантическую корректность).
\newline

Виды корректных преобразований:
\begin{enumerate}
    \item \textbf{Коммутативное}: $(R \Join_{RS} S)$ = $(S \Join_{SR} R)$
    \item \textbf{Ассоциативное}: $(R \Join_{RS} S) \Join_{RT,ST} T$ = $R \Join_{RS,RT} (S \Join_{ST} T)$
    \item \textbf{Левоассоциативное}: $(R \Join_{RS} S) \Join_{RT,ST} T$ = $(R \Join_{RT} T) \Join_{RS,ST} S$
    \item \textbf{Правоассоциативное}: $R \Join_{RS,RT} (S \Join_{ST} T)$ = $S \Join_{RS,ST} (R \Join_{RT} T)$
\end{enumerate}

\centering \subsection*{Жадный подход к планированию}

В статье "A New Heuristic for Optimizing Large Queries" --- Fegaras (1998) предлагается эвристический способ построения оптимального порядка, 
путём ухода от экспоненциального перебора порядков соединений, строя порядок соединений жадно снизу-вверх:
\begin{enumerate}
    \item На каждом шаге выбирать такое соединение, что даёт минимальный размер промежуточного результата, с учётом селективностей предикатов.
    \item Соединять выбранные поддеревья.
    \item Обновлять граф запроса новыми оценками размеров/селективностей.
\end{enumerate}

\begin{algorithm}[H]
\caption{GOO$(\{R_1,\dots,R_n\},\,\textit{weight}(T_1,T_2))$}
\begin{algorithmic}[1]
\Require set of relations to be joined
\Ensure join tree
\State $\textit{Trees} \gets \{R_1,\dots,R_n\}$
\While{$|\textit{Trees}| \neq 1$}
  \State find $T_i,T_j \in \textit{Trees}$ such that $i \neq j$ and
  $\textit{weight}(T_i,T_j)$ is minimal among all pairs of trees in $\textit{Trees}$
  \State $\textit{Trees} \gets \textit{Trees}\setminus \{T_i\}$
  \State $\textit{Trees} \gets \textit{Trees}\setminus \{T_j\}$
  \State $\textit{Trees} \gets \textit{Trees}\cup \{T_i \bowtie T_j\}$
\EndWhile
\State \Return the (only) tree contained in $\textit{Trees}$
\end{algorithmic}
\end{algorithm}

Преимущества:
\begin{enumerate}
    \item Эвристика строит ветвистые деревья, а не только левосторонние, что позволяет параллельно исполнять дерево плана.
    \item Полиномиальность по времени планирования $O(n^3)$, где $n$ --- число начальных отношений, вместо экспоненциального времени у подхода динамического программирования.
\end{enumerate}

Недостатки:
\begin{enumerate}
    \item Нет гарантий оптимальности: локально лучший шаг может загнать в глобально плохой порядок, классическая проблема жадных алгоритмов.
    \item Зависимость от качества оценок кардинальностей/селективностей: если оценки ошибочны, жадный подход резко деградирует.
\end{enumerate}

В этой статье также показывается связь с работой Ibaraki \& Kameda (1984). Так как в общем виде задача выбора оптимального порядка соединения отношений NP-трудная,
то планирование больших запросов требует больших вычислительных ресурсов, следовательно, нужны эвристики.
\newline

В современных СУБД самый распостранённый подход к планированию это \textbf{динамическое программирование}.
Алгоритмы динамического программирования — это методы решения задач оптимизации, которые разбивают исходную задачу на набор перекрывающихся подзадач 
и используют принцип оптимальности: оптимальное решение строится из оптимальных решений подзадач. Вместо повторного пересчёта результатов они их запоминают, 
снижая асимптотическую сложность по сравнению с полным перебором. Такие алгоритмы особенно эффективны, когда пространство решений можно 
параметризовать состояниями (например, подмножествами, интервалами, путями в графе). Цена за ускорение — рост памяти и экспоненциальное число состояний в худшем случае.
\newline


\centering \subsection*{Динамическое программирование по размеру подпланов (DPsize)}
В учебнике “Building Query Compilers” --- Moerkotte (2025) алгоритм DPsize рассматривается как вариант динамического программирования для построения
оптимального ветвистого (bushy) дерева соединений без декартовых произведений при условии, что граф соединений запроса связный.
Алгоритм перечисляет планы в порядке возрастания размера подпланов (числа отношений внутри подплана), что является обобщением схемы DP-Linear-1 на ветвистые деревья.

DPsize поддерживает таблицу $BestPlan(S)$, сопоставляющую каждому множеству отношений $S$ лучший (минимальной стоимости) найденный план, и строит планы снизу-вверх:
\begin{enumerate}
    \item Инициализация: для каждого отношения $R_i$ задаётся $BestPlan(\{R_i\}) = R_i$.
    \item Для размера плана $s = 2, \ldots, n$ (по возрастанию) перебираются разбиения $s = s_1 + s_2$, где $1 \le s_1 \le \lfloor s/2 \rfloor$.
    \item Для всех множеств $S_1, S_2$, уже имеющихся в $BestPlan$, таких что $|S_1| = s_1$, $|S_2| = s_2$, проверяется:
    \begin{enumerate}
        \item $S_1 \cap S_2 = \varnothing$ (подпланы не перекрываются),
        \item $S_1$ соединено с $S_2$ хотя бы одним предикатом.
    \end{enumerate}
    \item Если проверки пройдены, строится кандидат $CurrPlan = CreateJoinTree(BestPlan(S_1), BestPlan(S_2))$ и обновляется $BestPlan(S_1 \cup S_2)$, если кандидат дешевле.
\end{enumerate}

\begin{algorithm}[H]
    \begin{algorithmic}[1]
        \State \textbf{Input:} A set of relations $R = \{R_1, \dots, R_n\}$ to be joined
        \State \textbf{Output:} An optimal bushy join tree
        \State $B \gets$ an empty DP table $2^R \to$ join tree
        \For{\textbf{each} $R_i \in R$}
            \State $B[\{R_i\}] \gets R_i$
        \EndFor
        \For{\textbf{each} $1 < s \leq n$ \textbf{ascending}}
            \For{\textbf{each} $S_1, S_2 \subset R$ \textbf{such that} $|S_1| + |S_2| = s$}
                \If{(\textbf{not} cross products $\land \neg S_1$ connected to $S_2$) $\lor$ $(S_1 \cap S_2 \neq \emptyset)$}
                    \State \textbf{continue}
                \EndIf
                \State $p_1 \gets B[S_1], p_2 \gets B[S_2]$
                \If{$p_1 = \epsilon$ \textbf{or} $p_2 = \epsilon$} \textbf{continue} \EndIf
                \State $P \gets$ CreateJoinTree($p_1, p_2$)
                \If{$B[S_1 \cup S_2] = \epsilon$ \textbf{or} $C(B[S_1 \cup S_2]) > C(P)$}
                    \State $B[S_1 \cup S_2] \gets P$
                \EndIf
            \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}

Преимущества:
\begin{enumerate}
    \item Оптимальность (в рамках выбранной стоимостной модели и класса ветвистых деревьев без декартовых произведений):
    DPsize перебирает все допустимые склейки подпланов и сохраняет лучший результат для каждого множества $S$.
    \item Структурированное перечисление снизу-вверх по размеру подпланов: удобно для реализации и естественно соответствует принципу оптимальности динамического программирования.
    \item Зависимость времени от топологии: для цепей и циклов автор приводит полиномиальные формулы числа внутренних проверок (четвёртая степень по $n$),
    что объясняет практическую применимость DPsize на простых топологиях (цепочка, цикл).
\end{enumerate}

Недостатки:
\begin{enumerate}
    \item Худший случай экспоненциален: для звезды и полного графа число комбинаций резко возрастает.
    \item Далёк от нижней границы по перебору: в книге подчёркнуто, что DPsize (как и DPsub) перебирает существенно больше, чем необходимый минимум, что и мотивирует использовать DPccp.
\end{enumerate}

Сложность DPsize от числа отношений $n$:
\[
IDPsize_{\text{chain}}(n)=
\begin{cases}
\frac{1}{48}\left(5n^{4}+6n^{3}-14n^{2}-12n\right), & n\ \text{even},\\
\frac{1}{48}\left(5n^{4}+6n^{3}-14n^{2}-6n+11\right), & n\ \text{odd}.
\end{cases}
\]
\[
IDPsize_{\text{cycle}}(n)=
\begin{cases}
\frac{1}{4}\left(n^{4}-n^{3}-n^{2}\right), & n\ \text{even},\\
\frac{1}{4}\left(n^{4}-n^{3}-n^{2}+n\right), & n\ \text{odd}.
\end{cases}
\]
\[
IDPsize_{\text{star}}(n)=
\begin{cases}
2^{2n-4}-\frac{1}{4}\binom{2(n-1)}{n-1}+q(n), & n\ \text{even},\\
2^{2n-4}-\frac{1}{4}\binom{2(n-1)}{n-1}+\frac{1}{4}\binom{n-1}{(n-1)/2}+q(n), & n\ \text{odd},
\end{cases}
\]
\[
q(n) = n\cdot 2^{2n-1} - 5\cdot 2^{n-3} + \frac{1}{2}(n^{2}-5n+4).
\]
\[
IDPsize_{\text{clique}}(n)=
\begin{cases}
2^{2n-2}-5\cdot 2^{n-2}+\frac{1}{4}\binom{2n}{n}-\frac{1}{4}\binom{n}{n/2}+1, & n\ \text{even},\\
2^{2n-2}-5\cdot 2^{n-2}+\frac{1}{4}\binom{2n}{n}+1, & n\ \text{odd}.
\end{cases}
\]

\centering \subsection*{Динамическое программирование по подмножествам (DPsub)}
В “Building Query Compilers” --- Moerkotte DPsub описывается как вариант динамического программирования для построения оптимального ветвистого (bushy)
дерева соединений без декартовых произведений. В отличие от DPsize, где планы строятся по возрастанию размера подпланов, DPsub перебирает все непустые
подмножества исходного множества отношений и для каждого подмножества строит лучший план.

\begin{algorithm}[H]
    \begin{algorithmic}[1]
        \State \textbf{Input:} A set of relations $R = \{R_1, \dots, R_n\}$ to be joined
        \State \textbf{Output:} An optimal bushy join tree
        \State $B \gets$ an empty DP table $2^R \to$ join tree
        \For{\textbf{each} $R_i \in R$}
            \State $B[\{R_i\}] \gets R_i$
        \EndFor
        \For{\textbf{each} $1 < i \leq 2^n - 1$ \textbf{ascending}}
            \State $S \gets \{ R_j \in R \mid ( \lfloor i / 2^{j-1} \rfloor \mod 2) = 1 \}$
            \For{\textbf{each} $S_1, S_2 \subset S$ \textbf{such that} $S_2 = S \setminus S_1$}
                \If{(\textbf{not} cross products $\land \neg S_1$ connected to $S_2$)}
                    \State \textbf{continue}
                \EndIf
                \State $p_1 \gets B[S_1], p_2 \gets B[S_2]$
                \If{$p_1 = \epsilon$ \textbf{or} $p_2 = \epsilon$} \textbf{continue} \EndIf
                \State $P \gets$ CreateJoinTree($p_1, p_2$)
                \If{$B[S] = \epsilon$ \textbf{or} $C(B[S]) > C(P)$}
                    \State $B[S] \gets P$
                \EndIf
            \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}

Преимущества:
\begin{enumerate}
    \item Эффективен на плотных пространствах поиска (например, звезда/клика): в таких графах больше связных подмножеств и больше разбиений $S = S_1 \cup S_2$,
    проходящих проверки, поэтому доля холостых итераций меньше; на этих топологиях DPsub начинает выигрывать у DPsize.
    \item Оптимальность (в рамках выбранной стоимостной модели и класса ветвистых деревьев без декартовых произведений):
    DPsub перебирает все допустимые разбиения $S$ на две части и сохраняет лучший план для каждого $S$.
\end{enumerate}

Недостатки:
\begin{enumerate}
    \item Большое количество непройденных проверок для простых топологий (цепь/цикл): DPsub перебирает все подмножества $S$, но значительная часть из них несвязна,
    а для связных $S$ большая доля разбиений $(S_1, S_2)$ не проходит проверки связности/наличия предиката для соединения.
    \item Далёк от теоретической нижней границы: для большинства топологий число проверок во внутреннем цикле на порядки больше числа количества пар связных подграфов (\#ccp),
    что служит мотивацией перехода к DPccp.
\end{enumerate}

Сложность DPsub от числа отношений $n$:
\[
IDPsub_{\text{chain}}(n) = 2^{n+2} - n^{2} - 3n - 4,
\qquad
IDPsub_{\text{cycle}}(n) = n\cdot 2^{n} + 2^{n} - 2n^{2} - 2,
\]
\[
IDPsub_{\text{star}}(n) = 2\cdot 3^{n-1} - 2^{n},
\qquad
IDPsub_{\text{clique}}(n) = 3^{n} - 2^{n+1} + 1.
\]

\centering \subsection*{Динамическое программирование по csg-cmp-парам (DPccp)}

Пусть дан граф соединений $G = (V, E)$. Введём понятие csg-cmp-pair $(S_1, S_2)$ ---
в графе запроса выделим $S_1, S_2$ --- связные непересекающиеся подграфы, такие что $S_1 \subseteq V$,
$S_2 \subseteq V \setminus S_1$ (отсутствие пересечения) и существует между ними ребро.
$S_1, S_2$ в $(S_1, S_2)$ называются комплементарной парой.
\newline

Определим \#csg --- количество связных подграфов, в определении csg-cmp-pair это $S_1$ или $S_2$.
\newline

Определим \#ccp --- количество csg-cmp-pairs.
\newline

В [Analysis of Two Existing and One New Dynamic
Programming Algorithm for the Generation of Optimal
Bushy Join Trees without Cross Product] предлагается алгоритм DPccp как улучшение DPsize/DPsub для построения оптимального ветвистого дерева
соединений без декартовых произведений. Мотивация следующая: DPsize и DPsub тратят много итераций внутреннего цикла на проверки, которые часто не проходят,
и их объём работы может быть существенно больше теоретической нижней границы, задаваемой числом \#ccp.

DPccp поддерживает таблицу $BestPlan(S)$ и вместо перебора всех разбиений подмножеств рассматривает ровно csg-cmp-pairs:
\begin{enumerate}
    \item Инициализация: $BestPlan(\{R_i\}) = R_i$ для всех $R_i$.
    \item Перебор всех csg-cmp-pairs $(S_1, S_2)$; положим $S = S_1 \cup S_2$.
    \item Для текущей пары берутся $p_1 = BestPlan(S_1)$, $p_2 = BestPlan(S_2)$, строится кандидат $CurrPlan = CreateJoinTree(p_1, p_2)$ и обновляется $BestPlan(S)$,
    если кандидат дешевле.
    \item Так как процедура перечисления генерирует только одну ориентацию пары, алгоритм дополнительно учитывает коммутативность соединения, пробуя
    $CreateJoinTree(p_2, p_1)$.
\end{enumerate}

\begin{algorithm}[H]
\caption{DPccp}
\begin{algorithmic}[1]
\Require a connected query graph with relations $R=\{R_0,\dots,R_{n-1}\}$
\Ensure an optimal bushy join tree
\ForAll{$R_i \in R$}
    \State $\texttt{BestPlan}(\{R_i\}) \gets R_i$
\EndFor
\ForAll{csg-cmp-pairs $(S_1,S_2)$, $S = S_1 \cup S_2$}
    \State $\texttt{InnerCounter} \gets \texttt{InnerCounter} + 1$
    \State $\texttt{OnoLohmanCounter} \gets \texttt{OnoLohmanCounter} + 1$
    \State $p_1 \gets \texttt{BestPlan}(S_1)$
    \State $p_2 \gets \texttt{BestPlan}(S_2)$
    \State $\texttt{CurrPlan} \gets \texttt{CreateJoinTree}(p_1,p_2)$
    \If{$\texttt{cost}(\texttt{BestPlan}(S)) > \texttt{cost}(\texttt{CurrPlan})$}
        \State $\texttt{BestPlan}(S) \gets \texttt{CurrPlan}$
    \EndIf
    \State $\texttt{CurrPlan} \gets \texttt{CreateJoinTree}(p_2,p_1)$
    \If{$\texttt{cost}(\texttt{BestPlan}(S)) > \texttt{cost}(\texttt{CurrPlan})$}
        \State $\texttt{BestPlan}(S) \gets \texttt{CurrPlan}$
    \EndIf
\EndFor
\State $\texttt{CsgCmpPairCounter} \gets 2 \cdot \texttt{OnoLohmanCounter}$
\State \Return $\texttt{BestPlan}(\{R_0,\dots,R_{n-1}\})$
\end{algorithmic}
\end{algorithm}

Преимущества:
\begin{enumerate}
    \item Достижение нижней границы перебора: DPccp рассматривает ровно ccp; в тексте подчёркивается, что это является нижней границей для DP.
\end{enumerate}

Недостатки:
\begin{enumerate}
    \item Худший случай всё равно экспоненциален: на полных графах число \#ccp очень быстро возрастает, и DPccp также становится очень дорогим.
    \item Сложность реализации: нужно эффективно перечислять ccp без дубликатов и в порядке, корректном для DP,
    чтобы перед $(S_1, S_2)$ уже были рассмотрены все непустые подмножества.
\end{enumerate}

Сложность DPccp от числа отношений $n$:
\[
IDPccp_{\text{chain}}(n) = n^{3},\qquad
IDPccp_{\text{cycle}}(n) = n^{3},\qquad
IDPccp_{\text{star}}(n) = n^{2}2^{n},\qquad
IDPccp_{\text{clique}}(n) = 3^{n}.
\]

Алгоритм DPccp перечисляет csg-компоненты $S_1$ (связные подмножества) в порядке, согласованном с DP, используя BFS-нумерацию вершин и запрет на включение вершин с меткой меньше стартовой, чтобы не порождать дубликаты.
Для каждого $S_1$ процедура \texttt{EnumerateCmp} строит вторую часть пары $S_2$ только внутри дополнения $V\setminus S_1$: стартует с одиночных вершин из окрестности $N(S_1)$ и затем рекурсивно расширяет их, добавляя подмножества соседей уже построенного $S_2$ (то есть всегда растит связный компонент).
Параметр исключения $X$ выбирается так, чтобы $S_2$ не содержал вершин с меткой меньше любой вершины из $S_1$ (условие порядка $min(S_1) < min(S_2)$), что устраняет симметричные дубликаты $(S_1,S_2)$ / $(S_2,S_1)$.
Из-за старта из $N(S_1)$ и связного расширения гарантируется смежность $S_2$ к $S_1$ (есть ребро между компонентами), поэтому перечисляются ровно допустимые csg-cmp-пары без кросс-продуктов.

\centering \subsection*{DPhyp: динамическое программирование на гиперграфах}
[Dynamic Programming Strikes Back]
DPccp эффективен для \emph{простых} графов соединений (бинарные предикаты) и inner join: 
он перечисляет ровно csg-cmp-пары и тем самым близок к нижней границе перебора. Однако 
реальные запросы содержат \emph{сложные предикаты}, связывающие сразу несколько отношений, 
и \emph{non-inner joins} с ограничениями на перестановки. DPhyp обобщает DPccp на эти случаи 
за счёт представления запроса \emph{гиперграфом} и того же принципа перечисления ``осмысленных'' склеек.

\centering \subsubsection*{Гиперграф и csg-cmp-пары}
Запрос представим гиперграфом $H=(V,E)$, где $V$ --- отношения, а гиперребро $e=(U,W)$ связывает две непересекающиеся группы $U,W\subseteq V$, $U\cap W=\emptyset$ (частный случай $|U|=|W|=1$ даёт обычное ребро).
Подмножество $S\subseteq V$ называется \emph{csg} (connected subgraph), если индуцированный подграф связан.
Для csg-множества $S_1$ множество $S_2\subseteq V\setminus S_1$ называется \emph{cmp} (connected complement), если индуцированный подграф на $S_2$ связан.
Пара $(S_1,S_2)$ есть \emph{csg-cmp-пара}, если $S_1$ --- csg, $S_2$ --- cmp для $S_1$, и существует гиперребро $(U,W)\in E$ такое, что $U\subseteq S_1$ и $W\subseteq S_2$ (т.е. между компонентами есть предикат соединения).


\centering \subsubsection*{Идея перечисления}
DPhyp перечисляет только csg-cmp-пары, избегая массовых ``пустых'' проверок, характерных для DPsize/DPsub.
Вводится линейный порядок на отношениях $\prec$ и правило уникальности: рассматриваются только пары с $\min(S_1)\prec \min(S_2)$ (симметричные дубликаты не порождаются).
Компоненты строятся рекурсивным расширением через \emph{окрестность} $N(S,X)$ --- разрешённые узлы, ``достижимые'' из $S$ по гиперребрам, исключая запрещённые $X$.
Для гиперребра $(U,W)$, где $U\subseteq S$, в окрестность добавляется канонический вход $\min(W)$: это позволяет корректно инициировать построение второй стороны гиперребра и затем достраивать недостающие узлы.
\newline

Пусть есть цепочка $R_1\!-\!R_2\!-\!R_3$, цепочка $R_4\!-\!R_5\!-\!R_6$ и гиперребро между $\{R_1,R_2,R_3\}$ и $\{R_4,R_5,R_6\}$.
Тогда $(S_1,S_2)=(\{R_1,R_2,R_3\},\{R_4,R_5,R_6\})$ --- валидная csg-cmp-пара: обе стороны связны и соединяемы гиперребром.
Характерная ситуация: при $S_1=\{R_1,R_2,R_3\}$ окрестность даёт вход $\min(\{R_4,R_5,R_6\})=R_4$, и процедура \texttt{EnumerateCmpRec} достраивает $S_2$ до полной тройки, после чего пара становится соединяемой.

\begin{figure}[t]
\centering
\begin{tikzpicture}[node distance=8mm and 22mm]
  \node (R1) {$R_1$};
  \node (R2) [below=of R1] {$R_2$};
  \node (R3) [below=of R2] {$R_3$};

  \node (R4) [right=40mm of R1] {$R_4$};
  \node (R5) [below=of R4] {$R_5$};
  \node (R6) [below=of R5] {$R_6$};

  \node[inner sep=0pt, minimum size=0pt] (J1) [right=14mm of R2] {};
  \node[inner sep=0pt, minimum size=0pt] (J2) [left=14mm of R5] {};

  % простые ребра
  \draw (R1) -- (R2) -- (R3);
  \draw (R4) -- (R5) -- (R6);

  % гиперребро (как на Fig. 2)
  \draw (R1) -- (J1) -- (R3);
  \draw (J1) -- (J2);
  \draw (R4) -- (J2) -- (R6);
\end{tikzpicture}
\caption{Sample hypergraph}
\label{fig:dphyp-sample-hypergraph}
\end{figure}


\centering \subsubsection*{Псевдокод DPhyp}
\begin{verbatim}
Solve():
  for v in V: dp[{v}] = scan(v)
  for v in V (по убыванию ≺):
    EmitCsg({v})
    EnumerateCsgRec(S1={v}, X=Bv)     // Bv = {w | w ≺ v} ∪ {v}
  return dp[V]

EnumerateCsgRec(S1, X):
  for each nonempty N ⊆ N(S1, X):
    if connected(S1 ∪ N):
      EmitCsg(S1 ∪ N)
      EnumerateCsgRec(S1 ∪ N, X ∪ N(S1, X))

EmitCsg(S1):
  X = S1 ∪ Bmin(S1)
  for v in N(S1, X) (по убыванию ≺):
    S2 = {v}
    if joinable(S1, S2): EmitCsgCmp(S1, S2)
    EnumerateCmpRec(S1, S2, X)

EnumerateCmpRec(S1, S2, X):
  for each nonempty N ⊆ N(S2, X):
    if connected(S2 ∪ N) and joinable(S1, S2 ∪ N):
      EmitCsgCmp(S1, S2 ∪ N)
    EnumerateCmpRec(S1, S2 ∪ N, X)

EmitCsgCmp(S1, S2):
  S = S1 ∪ S2
  p = predicates_between(S1, S2)      // из всех гиперребер, пересекающих разрез
  dp[S] = min(dp[S], join(dp[S1], dp[S2], p))  // + вариант перестановки сторон
\end{verbatim}

Для non-inner joins порядок перестановок ограничен семантикой, поэтому часть разбиений заведомо невалидна.
Идея статьи: закодировать такие ограничения в структуре гиперграфа (добавляя ``ограничивающие'' гиперребра/предикаты), чтобы алгоритм DP перечислял только допустимые комбинации.
После этого DPhyp можно применять без изменения ядра алгоритма: ограничения автоматически проявляются как отсутствие соединяемых csg-cmp-пар.
Практический эффект --- резкое уменьшение пространства поиска по сравнению с DP, который проверяет валидность перестановок на каждом шаге.


\centering \subsection*{Генетический подход}
В работе Bennett, Ferris, Ioannidis (1991) предлагается генетический алгоритм (GA) для оптимизации запросов соединения как альтернатива классическому
динамическому программированию типа System~R.
Запрос рассматривается как дерево выполнения соединений (join processing tree), а качество решения определяется стоимостной моделью (cost) и переводится
в функцию приспособленности, которую GA максимизирует (обычно беря отрицание стоимости и масштабируя).
Алгоритм поддерживает популяцию планов кандидатов, итеративно применяя селекцию, кроссовер и мутацию.

\textbf{Ключевые идеи}
\begin{enumerate}
    \item Два пространства поиска (strategy spaces):
    \begin{enumerate}
        \item $L$ --- только left-deep планы (линейные деревья).
        \item $A$ --- более общее пространство, включающее bushy планы (ветвистые деревья).
    \end{enumerate}
    Мотивация: оптимальный план часто лежит вне $L$, поэтому для выигрыша по качеству требуется искать в $A$.
    \item Кодирование планов (chromosome encoding):
    \begin{enumerate}
        \item Для $L$: хромосома --- упорядоченный список генов вида (relation, join method).
        \item Для $A$: хромосома --- упорядоченный список генов, где каждый ген соответствует конкретному соединению из графа запроса,
        вместе с методом соединения и информацией о порядке (outer/inner).
    \end{enumerate}
    \item Декодирование и запрет декартовых произведений: декодирование строит дерево снизу-вверх и обеспечивает выполнимость;
    планы, порождающие декартовы произведения, штрафуются (например, бесконечной стоимостью),
    а генератор начальной популяции для left-deep старается создавать хромосомы без кросс-продуктов.
    \item Локальная селекция (local neighborhood GA): вместо глобальной селекции используется схема локальной окрестности (например, ring6),
    где отбор партнёров для скрещивания происходит внутри локального окружения хромосомы.
    \item Операторы поиска:
    \begin{enumerate}
        \item Мутации: (i) случайная смена метода соединения; (ii) локальная перестановка (swap) соседних генов.
        \item Кроссовер: два оператора --- M2S (modified two swap) и CHUNK (перенос случайного непрерывного фрагмента генов).
    \end{enumerate}
\end{enumerate}

\textbf{Преимущества}
\begin{enumerate}
    \item Масштабируемость для больших запросов: GA не требует хранения DP-таблиц экспоненциального размера и остаётся применимым там,
    где System~R становится непрактичным из-за памяти.
    \item Возможность улучшать планы относительно left-deep оптимума: поиск в $A$ позволяет находить ветвистые планы, которые по стоимости могут быть лучше лучшего left-deep плана.
    \item Хорошая параллелизуемость: популяционная природа GA естественно переносится на параллельную архитектуру с небольшими коммуникационными затратами.
\end{enumerate}

\textbf{Недостатки}
\begin{enumerate}
    \item Нет гарантий оптимальности и стабильности: по мере роста размера запроса качество решений и устойчивость сходимости ухудшаются из-за резкого роста пространства стратегий.
    \item Чувствительность к параметрам: качество зависит от размера популяции, выбора операторов кроссовера/мутации и схемы селекции; неудачные настройки дают деградацию.
    \item Затраты на оценку приспособленности: нужно многократно вычислять стоимость планов для большого числа хромосом, что может доминировать во времени оптимизации.
\end{enumerate}

\centering \subsection*{Использование графовых топологий при оценке эвристик}
В работе Allam (2018) порядок соединений рассматривается через граф запроса:
вершины --- отношения, рёбра --- предикаты соединения, веса рёбер --- селективности.
Автор использует типовые топологии (цепь, цикл, звезда, полный граф) как контролируемые модели различных классов графов соединений,
чтобы сравнить поведение алгоритмов на структурах с разной плотностью рёбер и диаметром.
Отдельно подчёркивается, что эффективность оптимизаторов зависит от структуры графа.
Например, цепь и звезда с одинаковым числом таблиц имеют разное время планирования.

\textbf{Подход: жадная эвристика и сравнение по топологиям}\\
Основной исследуемый алгоритм --- жадный подход, описанный выше.

\textbf{Ключевые идеи оценки}
\begin{enumerate}
    \item Сравнить жадный подход и динамическое программирование по двум метрикам: (i) стоимость найденного плана, (ii) время оптимизации (runtime).
    \item Выполнить сравнение на пяти графах: цепь, цикл, звезда, полный граф (синтетические топологии) и бенчмарке IMDB (реальный граф отношений),
    чтобы выявить влияние топологии на качество/время.
    \item Зафиксировать эмпирическое правило: для простых топологий (цепь и цикл) динамическое программирование доминирует по стоимости и часто по времени планирования,
    а для более сложных (звезда, полный граф) динамическое программирование остаётся лучшим по стоимости,
    но начинает резко проигрывать по времени планирования при росте числа отношений.
\end{enumerate}

\textbf{Преимущества жадного подхода}
\begin{enumerate}
    \item Полиномиальное время планирования и хорошая масштабируемость по времени планирования на больших запросах.
    \item Топологии показывают, что порог по числу таблиц недостаточен --- важна форма графа соединений.
\end{enumerate}

\textbf{Недостатки}
\begin{enumerate}
    \item Качество планов по стоимости хуже, чем у DP почти на всех топологиях.
    \item На IMDB жадный подход нестабилен по стоимости. Автор фиксирует большую разницу стоимости относительно синтетических топологий
    и существенно более высокие стоимости у GOO на большинстве размеров.
\end{enumerate}

\centering \subsection*{Адаптивная оптимизация очень больших запросов соединения}
В статье “Adaptive Optimization of Very Large Join Queries” --- Neumann \& Radke (2018) предлагается адаптивный фреймворк оптимизации порядка соединений,
который выбирает (и переключает) стратегию планирования по сложности графа соединений и заданному бюджету перебора,
чтобы для типичных запросов получать оптимум, а для больших деградировать по качеству плавно и предсказуемо по времени оптимизации.

\textbf{Понятие адаптивности}\\
Под адаптивностью в работе понимается не фиксированное правило вида ``DP до $N$ таблиц, дальше эвристика'',
а пер-запросный выбор алгоритма по структуре (топологии) графа запроса и контроль затрат оптимизации через бюджет перечисления.
В результате ``малые/простые'' запросы решаются точно, а ``длинный хвост'' (сотни и тысячи отношений) обрабатывается эвристически,
но с контролируемым временем оптимизации.

\textbf{Ключевые идеи и особенности адаптивного планирования}
\begin{enumerate}
    \item Оценка сложности через число связных подграфов и бюджет 10\,000.\\
    Авторы считают (с ранней остановкой) \#ccp графа соединений. Это число совпадает с размером полной DP-таблицы (а значит, с памятью DP и
    косвенно со временем оптимизации). Если число связных подграфов не превышает 10\,000, то графовый DP считается ``достаточно быстрым'',
    и запрос оптимизируется точно.
    \item Адаптивная стратегия (decision tree) вместо порога по числу отношений.\\
    Для $|V| < 14$ DPHyp запускается без подсчёта (клика --- худший случай, и примерно до 14 отношений DP ещё реалистичен).
    Для запросов до 100 отношений используется подсчёт \#ccp с бюджетом 10\,000; при успехе --- точный DPHyp,
    иначе происходит переход к следующей стадии. При наличии внешних соединений фреймворк выбирает другой путь.
    \item Search space linearization для ``medium'' запросов.\\
    Когда полный DP становится слишком дорогим, вводится линеаризация пространства поиска:
    сначала строится линейный порядок отношений, затем DP ограничивается только связными подцепочками этого порядка (connected subchains),
    вместо произвольных подмножеств. Это уменьшает размер DP-таблицы с $O(2^n)$ до $O(n^2)$ (и делает время порядка $O(n^3)$).
    Качество плана зависит от выбранного порядка: при ``плохой'' линеаризации некоторые хорошие порядки соединений становятся недостижимыми.
    Кроме того, гипер-рёбра не выражаются линейно, поэтому linearized DP применима только к обычным графам соединений.
    \item GOO + локальная оптимизация больших поддеревьев под бюджет (для ``large/mega'').\\
    Для очень больших запросов строится начальный план жадной эвристикой (GOO), после чего выполняется итеративное улучшение:
    выбранные (дорогие) поддеревья перепланируются более точным методом DP, но только до размера $k$.
    В обычном случае в роли ``внутреннего DP'' используется linearizedDP и берётся $k \approx 100$, что позволяет исправлять крупные фрагменты плана.
    Если в запросе есть не внутренние соединения, то вместо linearizedDP приходится использовать DPHyp,
    поэтому берут существенно меньший $k \approx 10$. Бюджет оптимизации расходуется явно:
    после каждого вызова внутреннего DP уменьшают оставшийся бюджет,
    что обеспечивает ограничение по времени оптимизации и ``плавное'' ухудшение качества без резкого обрыва.
\end{enumerate}

\textbf{Преимущества}
\begin{enumerate}
    \item Оптимальность для частого случая: если граф достаточно простой по \#ccp бюджету, фреймворк гарантированно запускает DPHyp и находит оптимальный порядок.
    \item Масштабирование до тысяч отношений: при росте размера запроса происходит переход к менее дорогим стадиям (linearizedDP, затем GOO+DP на поддеревьях),
    что позволяет работать с ``длинным хвостом'' размеров запросов.
    \item Плавная деградация качества: вместо жёсткого переключения ``DP $\to$ greedy'' вводятся промежуточные стадии и улучшение крупных подпроблем DP,
    что снижает разрыв по качеству планов.
    \item Учитывается форма графа запроса: выбор алгоритма определяется не только числом начальных отношений, что точнее отражает реальную сложность перечисления.
\end{enumerate}

\textbf{Ограничения и недостатки}
\begin{enumerate}
    \item Ограниченная применимость линеаризации: linearizedDP неприменима при внешних соединениях и гипер-рёбрах,
    поэтому для таких запросов качество/скорость хуже (внутренний DP тяжелее, а $k$ приходится уменьшать).
    \item Зависимость качества от линеаризации: выбранный линейный порядок ограничивает пространство планов, следовательно, некоторые хорошие порядки соединений становятся недостижимыми.
    \item Локальность улучшений в GOO-DP: перепланирование поддеревьев размера $k$ не даёт полной свободы глобальных перестановок между различными поддеревьями,
    поэтому итог может оставаться далёким от оптимума на ``трудных'' структурах.
    \item Пороговые параметры являются эвристическими: бюджет, границы и $k$ определяют поведение и требуют настройки под конкретную систему и модель стоимости.
\end{enumerate}

\centering \subsection*{Оценки в модели стоимости}
[How Good Are Query Optimizers, Really?]
\newline

Оптимизатор СУБД выбирает план выполнения по стоимостной модели, опираясь на оценки селективностей и кардинальностей 
промежуточных результатов. Если эти оценки сильно ошибочны (что часто происходит из-за предположений о независимости предикатов 
и упрощённых статистик), оптимизатор может выбрать плохой порядок соединений и неподходящие алгоритмы, что приводит к кратному 
(иногда на порядки) замедлению выполнения запроса.
\newline

Авторы предлагают измерять качество оптимизатора не абстрактно, а на контролируемой постановке: берётся набор реальных сложных 
запросов и сравниваются (1) ошибки оценок кардинальностей и (2) итоговое время выполнения при разных условиях. Используется 
Join Order Benchmark (JOB) на базе IMDb: 113 запросов с множественными соединениями и фильтрами.
Ключевой приём: модифицируется PostgreSQL так, чтобы оптимизатор мог получать \emph{истинные} кардинальности 
(как будто статистика идеальна). Это позволяет отделить влияние ошибок оценок от прочих факторов и ответить на вопрос: насколько улучшится план и время выполнения, если убрать только ошибки селективности/кардинальности.
Дополнительно анализируется роль качества стоимостной модели и объёма перебора планов 
(полный DP-поиск против ограниченных эвристик).
\newline

Выводы:
\begin{enumerate}
\item Ошибки оценок кардинальностей встречаются часто и могут быть очень большими, особенно в запросах с множеством соединений и коррелированными условиями. 
\item Главный источник плохих планов --- именно ошибки кардинальностей: при доступе к точным размерам оптимизатор существенно чаще выбирает правильный порядок соединений и более подходящие алгоритмы, что заметно ускоряет выполнение.
\item Точность самой стоимостной функции оказывает меньший эффект: упрощение параметров стоимости обычно меньше влияет на качество плана, чем исправление кардинальностей.
\item Полноценный перебор (динамическое программирование для join order) даёт преимущество над ограниченными стратегиями поиска: даже при неточных оценках он реже пропускает хороший порядок соединений, тогда как ограниченный поиск может застрять на неудачном плане.
\item При этом оптимизатор часто остаётся ``достаточно хорошим'' на практике: многие планы устойчивы к ошибкам (например, хеш-соединения), а катастрофические провалы возникают в сравнительно редких сочетаниях (глубокие деревья соединений + сильные ошибки + рискованные выборы вроде больших nested-loop).
\end{enumerate}

\end{flushleft}